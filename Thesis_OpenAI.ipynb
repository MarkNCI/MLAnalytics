{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q\n",
        "!pip install streamlit -q\n",
        "!pip install openai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5jHrh6L68YE",
        "outputId": "143a23a0-7a16-4331-e3bc-51869e09dfd1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oE6FqPD5Yyy",
        "outputId": "2e4377ca-8204-4bae-b602-df404773a81b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import openai, requests, os\n",
        "\n",
        "# Intro Text\n",
        "st.markdown('# PDF summarization using Generative AI')\n",
        "st.header('''PDF size must be below 200MB. Only 1 PDF per time, time will vary depending on size''')\n",
        "\n",
        "input_file = st.file_uploader('Upload a PDF file')\n",
        "\n",
        "# Save uploaded file\n",
        "if input_file:\n",
        "  with open(os.path.join(input_file.name),'wb') as f:\n",
        "        f.write(input_file.getbuffer())\n",
        "  st.success('Saved File')\n",
        "\n",
        "st.markdown('# Summary')\n",
        "\n",
        "def summarise_file(prompt,model = 'gpt-3.5-turbo'):\n",
        "  # Connect to API endpoint\n",
        "  openai.api_key = ''\n",
        "  URL = 'https://api.openai.com/v1/chat/completions'\n",
        "\n",
        "  parameters = {\n",
        "      'model':model,\n",
        "      'messages': [{'role':'user', 'content':prompt}],\n",
        "      'temperature': 1,\n",
        "      'top_p': 1\n",
        "  }\n",
        "\n",
        "  headers = {\n",
        "      'Content-Type': 'application/json',\n",
        "      'Authorization': f'Bearer {openai.api_key}'\n",
        "  }\n",
        "\n",
        "  response = requests.post(URL, headers=headers, json=parameters, stream=False)\n",
        "  json_response = response.json()\n",
        "  summary = json_response['choices'][0]['message']['content'].strip()\n",
        "  return summary\n",
        "\n",
        "\n",
        "def keywords(prompt,model = 'gpt-3.5-turbo'):\n",
        "  # Connect to API endpoint\n",
        "  openai.api_key = ''\n",
        "  URL = 'https://api.openai.com/v1/chat/completions'\n",
        "\n",
        "  parameters = {\n",
        "      'model':model,\n",
        "      'messages': [{'role':'user', 'content':prompt}],\n",
        "      'temperature': 1,\n",
        "      'top_p': 1\n",
        "  }\n",
        "\n",
        "  headers = {\n",
        "      'Content-Type': 'application/json',\n",
        "      'Authorization': f'Bearer {openai.api_key}'\n",
        "  }\n",
        "\n",
        "  response = requests.post(URL, headers=headers, json=parameters, stream=False)\n",
        "  json_response = response.json()\n",
        "  summary = json_response['choices'][0]['message']['content'].strip()\n",
        "  return summary\n",
        "\n",
        "if input_file:\n",
        "  prompt = f'''\n",
        "  ### TASK\n",
        "  You are an expert in text analysis and summarisation with research papers. Your task is to analyse a research paper I'm going to give you\n",
        "  and provide a detailed summary that is most representative of its content. You must use the Key Concept Clarity method to read the paper and\n",
        "  highlight all of the key talking points of the paper.\n",
        "  ### INPUTS\n",
        "  Research Paper: {input_file}\n",
        "  ### OUTPUT\n",
        "  The output should be structured so as to identify and concisely explain the main ideas in the document. Each section should consist of the\n",
        "  name of the talking point, a detailed definition of the talking point and a short summary of the talking point.\n",
        "  Aim to provide at least five talking points. Here is how each talking point should be structured:\n",
        "  Title: Name of the talking point\n",
        "  Explanation: Define in detail what is the talking point\n",
        "  Overview: Provide a short summary of the talking point including its challenges ,if any, and findings.\n",
        "  '''\n",
        "  text_area = summarise_file(prompt)\n",
        "  st.success('Summary lodaing, please wait...')\n",
        "\n",
        "  # Show Summary\n",
        "  st.success('Summary ready!')\n",
        "  st.text_area(label =\"\",value= text_area, placeholder=\"Please upload a PDF to get it's summary\", height = 400)\n",
        "  st.markdown('')\n",
        "\n",
        "  prompt = f'''\n",
        "  ### TASK\n",
        "  You are an expert in creating abstracts from research papers and finding similar abstracts. Your task is to analyse a research paper I'm going\n",
        "  to give you and create an abstract that is most representative of its content. Then you're going to searcg https://arxiv.org/ and return the\n",
        "  names and urls of the top 5 results.\n",
        "  ### INPUTS\n",
        "  Summary: {input_file}\n",
        "  ### OUTPUT\n",
        "  For each result, provide a short explanation of why you think the two abstracts are similar.\n",
        "  '''\n",
        "  test = keywords(prompt)\n",
        "  st.success('Recommendations lodaing, please wait...')\n",
        "  # Show Summary\n",
        "  st.success('Recommendations ready!')\n",
        "  st.text_area(label =\"\",value= test, placeholder=\"Please upload a PDF to get it's summary\", height = 400)\n",
        "  st.markdown('')\n",
        "\n",
        "else:\n",
        "  st.text_area(label =\"\",value= \"Please upload a PDF to get it's summary\", placeholder=\"Please upload a PDF to get it's summary\", height = 400)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khiFwlxK9FVl",
        "outputId": "0e3be3e8-7176-4a6c-92d3-4f7e49a943b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors in 5.096s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wQvJHmR8-_J",
        "outputId": "8ac53d22-d8a7-461e-83b2-dac552017999"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.106.218.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>./logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf5l7uo19BtD",
        "outputId": "cd1ce3ed-74f3-4b75-aed6-ffe8aee0fd7d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.909s\n",
            "your url is: https://shaky-showers-stay.loca.lt\n",
            "/root/.npm/_npx/1058/lib/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:41117 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/root/.npm/_npx/1058/lib/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (events.js:315:20)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (internal/streams/destroy.js:106:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (internal/streams/destroy.js:74:3)\u001b[39m\n",
            "\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m\n"
          ]
        }
      ]
    }
  ]
}