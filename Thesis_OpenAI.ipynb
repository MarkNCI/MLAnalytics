{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q\n",
        "!pip install streamlit -q\n",
        "!pip install openai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5jHrh6L68YE",
        "outputId": "4c5a97b5-7df4-48bf-b8e2-92fd854153b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oE6FqPD5Yyy",
        "outputId": "8fa299b3-b0b2-4eed-8f7b-2c2e15aed0bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import openai, requests, os\n",
        "\n",
        "openai.api_key = ''\n",
        "\n",
        "# Intro Text\n",
        "st.markdown('# PDF summarization using Generative AI')\n",
        "st.header('''PDF size must be below 200MB. Only 1 PDF per time, time will vary depending on size''')\n",
        "\n",
        "input_file = st.file_uploader('Upload a PDF file')\n",
        "\n",
        "# Save uploaded file\n",
        "if input_file:\n",
        "  with open(os.path.join(input_file.name),'wb') as f:\n",
        "        f.write(input_file.getbuffer())\n",
        "  st.success('Saved File')\n",
        "\n",
        "st.markdown('# Summary')\n",
        "\n",
        "def summarise_file(prompt,model = 'gpt-3.5-turbo'):\n",
        "  # Connect to API endpoint\n",
        "  URL = 'https://api.openai.com/v1/chat/completions'\n",
        "\n",
        "  parameters = {\n",
        "      'model':model,\n",
        "      'messages': [{'role':'user', 'content':prompt}],\n",
        "      'temperature': 1,\n",
        "      'top_p': 1\n",
        "  }\n",
        "\n",
        "  headers = {\n",
        "      'Content-Type': 'application/json',\n",
        "      'Authorization': f'Bearer {openai.api_key}'\n",
        "  }\n",
        "\n",
        "  response = requests.post(URL, headers=headers, json=parameters, stream=False)\n",
        "  json_response = response.json()\n",
        "  summary = json_response['choices'][0]['message']['content'].strip()\n",
        "  return summary\n",
        "\n",
        "\n",
        "def keywords(prompt,model = 'gpt-3.5-turbo'):\n",
        "  # Connect to API endpoint\n",
        "  URL = 'https://api.openai.com/v1/chat/completions'\n",
        "\n",
        "  parameters = {\n",
        "      'model':model,\n",
        "      'messages': [{'role':'user', 'content':prompt}],\n",
        "      'temperature': 1,\n",
        "      'top_p': 1\n",
        "  }\n",
        "\n",
        "  headers = {\n",
        "      'Content-Type': 'application/json',\n",
        "      'Authorization': f'Bearer {openai.api_key}'\n",
        "  }\n",
        "\n",
        "  response = requests.post(URL, headers=headers, json=parameters, stream=False)\n",
        "  json_response = response.json()\n",
        "  summary = json_response['choices'][0]['message']['content'].strip()\n",
        "  return summary\n",
        "\n",
        "if input_file:\n",
        "  prompt = f'''\n",
        "  ### TASK\n",
        "  You are an expert in text analysis and summarisation with research papers. Your task is to analyse a research paper I'm going to give you\n",
        "  and provide a detailed summary that is most representative of its content. You must use the Key Concept Clarity method to read the paper and\n",
        "  highlight all of the key talking points of the paper.\n",
        "  ### INPUTS\n",
        "  Research Paper: {input_file}\n",
        "  ### OUTPUT\n",
        "  The output should be structured so as to identify and concisely explain the main ideas in the document. Each section should consist of the\n",
        "  name of the talking point, a detailed definition of the talking point and a short summary of the talking point.\n",
        "  Aim to provide at least five talking points. Here is how each talking point should be structured:\n",
        "  Title: Name of the talking point\n",
        "  Explanation: Define in detail what is the talking point\n",
        "  Overview: Provide a short summary of the talking point including its challenges ,if any, and findings.\n",
        "  '''\n",
        "  text_area = summarise_file(prompt)\n",
        "  st.success('Summary loading, please wait...')\n",
        "\n",
        "  # Show Summary\n",
        "  st.success('Summary ready!')\n",
        "  st.text_area(label =\"\",value= text_area, placeholder=\"Please upload a PDF to get it's summary\", height = 400)\n",
        "  st.markdown('')\n",
        "\n",
        "  prompt = f'''\n",
        "  ### TASK\n",
        "  You are an expert in text analysis and keyword extraction. Your task is to analyse a research paper I'm going\n",
        "  to give you and extract from it the top 5 keywords that are most representative of its content especially the points made in the first\n",
        "  paragraph. Then you're going to convert the keywords to lower case abd search https://arxiv.org/ and return the names and urls of the top 5\n",
        "  results. The url you will use is http://export.arxiv.org/api/query?search_query=all:keyword&start=0&max_results=5. If the keyword is more\n",
        "  than one word seperate with a + symbol such as machine+learning.\n",
        "  ### INPUTS\n",
        "  Summary: {input_file}\n",
        "  ### OUTPUT\n",
        "  The list of results you're going to generate should be in descending order from the most relevant to the least relevant.\n",
        "  '''\n",
        "  test = keywords(prompt)\n",
        "  st.success('Recommendations loading, please wait...')\n",
        "  # Show Summary\n",
        "  st.success('Recommendations ready!')\n",
        "  st.text_area(label =\"\",value= test, placeholder=\"Please upload a PDF to get it's summary\", height = 400)\n",
        "  st.markdown('')\n",
        "\n",
        "else:\n",
        "  st.text_area(label =\"\",value= \"Please upload a PDF to get it's summary\", placeholder=\"Please upload a PDF to get it's summary\", height = 400)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the below back in"
      ],
      "metadata": {
        "id": "A4OXZQyOtdo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You are an expert in creating abstracts from research papers and finding similar abstracts. Your task is to analyse a research paper I'm going\n",
        "#   to give you and create an abstract that is most representative of its content especially the points made in the first paragraph. Then you're\n",
        "#   going to search https://arxiv.org/ and return the names and urls of the top 5 results.\n",
        "#   ### INPUTS\n",
        "#   Summary: {input_file}\n",
        "#   ### OUTPUT\n",
        "#   For each result, provide a short explanation of why you think the two abstracts are similar."
      ],
      "metadata": {
        "id": "JpD3avJreuPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rerun this if error"
      ],
      "metadata": {
        "id": "T-VT_obdVm7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khiFwlxK9FVl",
        "outputId": "8bacb429-3f7f-4368-8009-121d7d03ed6b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package in 0.988s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wQvJHmR8-_J",
        "outputId": "c1488e76-8d16-46f1-a7a9-ede89ed46a8a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.75.3.129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>./logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf5l7uo19BtD",
        "outputId": "c5ef38f8-29de-4f09-ecf3-60decec995f9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.833s\n",
            "your url is: https://brave-parrots-yawn.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}